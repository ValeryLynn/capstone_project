{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Itâ€™s Time to Make Some Crazy Money!</center></h1>\n",
    "<h1><center>Predicting a NYC Taxi Trip Duration</center></h1>\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Modeling](#modeling)\n",
    "    1. [Split Data](#split)\n",
    "    2. [Scale data](#scale)\n",
    "    3. [RMSLE](#metric)\n",
    "    4. [Linear Regression](#linear)\n",
    "    5. [Support Vector Machine](#svm)\n",
    "    6. [Random Forest](#rforest)\n",
    "    7. [XGBoost](#xgboost)\n",
    "    8. [Tuning XGBoost](#tuning)\n",
    "2. [Conclusion](#conclusion)\n",
    "    1. [Results](#results)\n",
    "    2. [Recommendations](#recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries <a name=\"libraries\"></a>\n",
    "***\n",
    "These are some of the libraries used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data <a name=\"acquire\"></a>\n",
    "***\n",
    "The data was acquired from a Kaggle's Competition called [New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration). The data has been previously [cleaned](https://github.com/emmpew/datascience/blob/master/capstone_project/data_cleaning.ipynb) and is ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_train_data.csv')\n",
    "test = pd.read_csv('cleaned_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data content <a name=\"content\"></a>\n",
    "***\n",
    "Let's look at the content of the data such as shape, columns, and summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>store_and_fwd_flag_Y</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>direct_distance</th>\n",
       "      <th>pickup_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.98215</td>\n",
       "      <td>40.76794</td>\n",
       "      <td>-73.96463</td>\n",
       "      <td>40.76560</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.933406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.98042</td>\n",
       "      <td>40.73856</td>\n",
       "      <td>-73.99948</td>\n",
       "      <td>40.73115</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.123849</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.97903</td>\n",
       "      <td>40.76394</td>\n",
       "      <td>-74.00533</td>\n",
       "      <td>40.71009</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.964154</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-74.01004</td>\n",
       "      <td>40.71997</td>\n",
       "      <td>-74.01227</td>\n",
       "      <td>40.70672</td>\n",
       "      <td>429.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.921886</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.97305</td>\n",
       "      <td>40.79321</td>\n",
       "      <td>-73.97292</td>\n",
       "      <td>40.78252</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.737591</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  vendor_id  passenger_count  pickup_longitude  \\\n",
       "0           0           0.0        2.0              1.0         -73.98215   \n",
       "1           1           1.0        1.0              1.0         -73.98042   \n",
       "2           2           2.0        2.0              1.0         -73.97903   \n",
       "3           3           3.0        2.0              1.0         -74.01004   \n",
       "4           4           4.0        2.0              1.0         -73.97305   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  trip_duration  \\\n",
       "0         40.76794          -73.96463          40.76560          455.0   \n",
       "1         40.73856          -73.99948          40.73115          663.0   \n",
       "2         40.76394          -74.00533          40.71009         2124.0   \n",
       "3         40.71997          -74.01227          40.70672          429.0   \n",
       "4         40.79321          -73.97292          40.78252          435.0   \n",
       "\n",
       "   store_and_fwd_flag_Y  pickup_month  pickup_hour  direct_distance  \\\n",
       "0                   0.0           3.0         17.0         0.933406   \n",
       "1                   0.0           6.0          0.0         1.123849   \n",
       "2                   0.0           1.0         11.0         3.964154   \n",
       "3                   0.0           4.0         19.0         0.921886   \n",
       "4                   0.0           3.0         13.0         0.737591   \n",
       "\n",
       "   pickup_weekday  \n",
       "0             0.0  \n",
       "1             6.0  \n",
       "2             1.0  \n",
       "3             2.0  \n",
       "4             5.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1450268, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'vendor_id', 'passenger_count',\n",
       "       'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
       "       'dropoff_latitude', 'trip_duration', 'store_and_fwd_flag_Y',\n",
       "       'pickup_month', 'pickup_hour', 'direct_distance', 'pickup_weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1450268 entries, 0 to 1450267\n",
      "Data columns (total 14 columns):\n",
      "Unnamed: 0              1450268 non-null int64\n",
      "Unnamed: 0.1            1450268 non-null float64\n",
      "vendor_id               1450268 non-null float64\n",
      "passenger_count         1450268 non-null float64\n",
      "pickup_longitude        1450268 non-null float64\n",
      "pickup_latitude         1450268 non-null float64\n",
      "dropoff_longitude       1450268 non-null float64\n",
      "dropoff_latitude        1450268 non-null float64\n",
      "trip_duration           1450268 non-null float64\n",
      "store_and_fwd_flag_Y    1450268 non-null float64\n",
      "pickup_month            1450268 non-null float64\n",
      "pickup_hour             1450268 non-null float64\n",
      "direct_distance         1450268 non-null float64\n",
      "pickup_weekday          1450268 non-null float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 154.9 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modeling <a name='modeling'></a>\n",
    "***\n",
    "Now after cleaning the data, let's use the training dataset to train the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data  <a name='split'></a>\n",
    "***\n",
    "Now that the test dataset is ready let's split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('trip_duration',axis=1)\n",
    "y_train = train['trip_duration']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.30, random_state=102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data <a name='scale'></a>\n",
    "***\n",
    "Let's scale the data in a range from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train_scaled = scaler.fit_transform(X_train) \n",
    "# X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSLE <a name='metric'></a>\n",
    "***\n",
    "Metrics used to evaluate models are problem specific. In this case, [Root Mean Squared Logarithmic Error](https://www.kaggle.com/wiki/RootMeanSquaredLogarithmicError) is the metric required for this problem. So the goal is to minimize the RMSLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true,y_pred):\n",
    "   assert len(y_true) == len(y_pred)\n",
    "   return np.square(np.log(y_pred + 1) - np.log(y_true + 1)).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression <a name='linear'></a>\n",
    "***\n",
    "The goal with linear regression is to minimize the vertical distance between all the data points and the regression line. So in determining the best line, we are attempting to minimize the distance between all the points and their distance to the regression line.\n",
    "\n",
    "Let's use linear regression to have a baseline of a model and from there implement other models that reduce the error. GridSearchCV will allow us to do cross validation and hyperparameter tuning at the same time. The following parameters will be tuned:\n",
    "\n",
    "- fit_intercept: wheter to calculate the intercept for this model, meaning that if False, the intercept $\\beta_0$ from our linear regression equation will be 0.\n",
    "- normalize: to normalize the data before regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 4.73 s, total: 22.8 s\n",
      "Wall time: 16.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'fit_intercept': [True, False], 'normalize': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'fit_intercept':[True,False], 'normalize':[True,False]}\n",
    "\n",
    "linreg_cv = GridSearchCV(LinearRegression(),params, cv=5)\n",
    "%time linreg_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 ms, sys: 26 ms, total: 62 ms\n",
      "Wall time: 78.2 ms\n",
      "Best Parameters: {'fit_intercept': True, 'normalize': False}\n",
      "Best score is 0.6131640434846093\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = linreg_cv.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters: {}\".format(linreg_cv.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5397417884235575"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R-Squared: 55.79%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model R-Squared: {:.2f}%\".format(100*linreg_cv.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With one of the simplest linear models, the baseline rmsle is **0.5397**. $R^2$ is the percentage of the response variable variation that is explained by a linear model. In general, the higher the R-squared, the better the model fits your data. So the linear regression model explains **55.79%** of the variability of the response data around its mean. Now it is time to implement a more complex model such as Support Vector Machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM <a name='svm'></a>\n",
    "***\n",
    "Support Vector Machines are supervised learning models with associated learning algorithms that analyze data and recognize patterns. It can be used for both regression and classification; however, in this case, we will use it for regression. \n",
    "\n",
    "Let's use LinearSVR since it scales to large number of samples. First, create a pipeline and scale the data before using the SVM model. GridSearchCV will allow us to do cross validation and hyperparameter tuning at the same time. The following parameters will be tuned: \n",
    "\n",
    "- c: slack variable which allows the decision boundary to have some slack, meaning the model allows some misclassification. If we make c really small, we introduce more slack and get a more stable decision hyperplane. For regression, the influence of c is similar. You get less support vectors and get a smoother prediction. The slack variable allows for regression errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()),\n",
    "         ('svr', LinearSVR())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {'svr__C':[0.1,1,10]}\n",
    "\n",
    "svr_cv = GridSearchCV(pipeline,params,cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] svr__C=0.1 ......................................................\n",
      "[CV] ............. svr__C=0.1, score=0.6003053797518216, total=   2.0s\n",
      "[CV] svr__C=0.1 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. svr__C=0.1, score=0.5961437680743831, total=   2.5s\n",
      "[CV] svr__C=0.1 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. svr__C=0.1, score=0.5902271852026608, total=   2.6s\n",
      "[CV] svr__C=0.1 ......................................................\n",
      "[CV] ............. svr__C=0.1, score=0.5955791402350598, total=   2.2s\n",
      "[CV] svr__C=0.1 ......................................................\n",
      "[CV] ............. svr__C=0.1, score=0.6010509508008012, total=   2.2s\n",
      "[CV] svr__C=1 ........................................................\n",
      "[CV] ............... svr__C=1, score=0.6002570065375781, total=   3.1s\n",
      "[CV] svr__C=1 ........................................................\n",
      "[CV] ............... svr__C=1, score=0.5961128905325311, total=   3.1s\n",
      "[CV] svr__C=1 ........................................................\n",
      "[CV] ............... svr__C=1, score=0.5904125583663745, total=   3.2s\n",
      "[CV] svr__C=1 ........................................................\n",
      "[CV] ............... svr__C=1, score=0.5956627798078467, total=   4.4s\n",
      "[CV] svr__C=1 ........................................................\n",
      "[CV] ............... svr__C=1, score=0.6012479443593219, total=   4.4s\n",
      "[CV] svr__C=10 .......................................................\n",
      "[CV] .............. svr__C=10, score=0.6003675540899003, total=  15.1s\n",
      "[CV] svr__C=10 .......................................................\n",
      "[CV] .............. svr__C=10, score=0.5957696729128086, total=  12.4s\n",
      "[CV] svr__C=10 .......................................................\n",
      "[CV] .............. svr__C=10, score=0.5902220099590534, total=  12.5s\n",
      "[CV] svr__C=10 .......................................................\n",
      "[CV] ............... svr__C=10, score=0.595655222633587, total=  14.0s\n",
      "[CV] svr__C=10 .......................................................\n",
      "[CV] .............. svr__C=10, score=0.6013370891441097, total=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 6.56 s, total: 1min 40s\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'svr__C': [0.1, 1, 10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time svr_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 79.7 ms, sys: 51.8 ms, total: 131 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = svr_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'svr__C': 1}\n",
      "Best score is 0.5967386387700826\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: {}\".format(svr_cv.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4899128923052467"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R-Squared: 50.38%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model R-Squared: {:.2f}%\".format(100*svr_cv.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a value of **0.4899**, RMSLE decreased compared to linear regression which is our main goal. It is also important to mention that the model $R^2$ decreased to **50.38%**. The best slack value is 1.0. Now let's move on to more powerful and popular machine learning algorithms, ensemble methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest <a name='rforest'></a>\n",
    "***\n",
    "Random Forest generates bootstrap training samples (sample with replacement from the data set), and for each one it creates a tree. However, it doesn't just randomize the training samples, it also randomizes a set of predictors allowed to use each time a split is considered which is called bagging. It is harder to interpret but the predictive accuracy tends to be a lot better than compared to doing it just for one tree and superior to other methods as well.\n",
    "\n",
    "Let's use RandomForestRegressor combined with GridSearchCV will allow us to do cross validation and hyperparameter tuning at the same time. The following parameters will be tuned:\n",
    "\n",
    "- max_features: the number of features to consider when looking for the best split. Usually the default works so for simplicity let's use only 'auto'.\n",
    "- n_estimators: The number of trees in the forest. Let's use lower number of trees due to the large amount of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] max_features=auto, n_estimators=20 ..............................\n",
      "[CV]  max_features=auto, n_estimators=20, score=0.7933373924964942, total= 4.3min\n",
      "[CV] max_features=auto, n_estimators=20 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=20, score=0.7964785882110328, total= 4.1min\n",
      "[CV] max_features=auto, n_estimators=20 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=auto, n_estimators=20, score=0.7817344300187744, total= 4.3min\n",
      "[CV] max_features=auto, n_estimators=20 ..............................\n",
      "[CV]  max_features=auto, n_estimators=20, score=0.7971821006507348, total= 4.1min\n",
      "[CV] max_features=auto, n_estimators=20 ..............................\n",
      "[CV]  max_features=auto, n_estimators=20, score=0.7909912608758295, total= 4.1min\n",
      "[CV] max_features=auto, n_estimators=30 ..............................\n",
      "[CV]  max_features=auto, n_estimators=30, score=0.7973523359735892, total= 6.2min\n",
      "[CV] max_features=auto, n_estimators=30 ..............................\n",
      "[CV]  max_features=auto, n_estimators=30, score=0.7999287823472977, total= 6.2min\n",
      "[CV] max_features=auto, n_estimators=30 ..............................\n",
      "[CV]  max_features=auto, n_estimators=30, score=0.7849311376879485, total= 6.3min\n",
      "[CV] max_features=auto, n_estimators=30 ..............................\n",
      "[CV]  max_features=auto, n_estimators=30, score=0.8006401406250621, total= 6.0min\n",
      "[CV] max_features=auto, n_estimators=30 ..............................\n",
      "[CV]  max_features=auto, n_estimators=30, score=0.7952415586035255, total= 6.3min\n",
      "[CV] max_features=auto, n_estimators=40 ..............................\n",
      "[CV]  max_features=auto, n_estimators=40, score=0.7996088353162267, total= 8.3min\n",
      "[CV] max_features=auto, n_estimators=40 ..............................\n",
      "[CV]  max_features=auto, n_estimators=40, score=0.8020606834681654, total= 8.1min\n",
      "[CV] max_features=auto, n_estimators=40 ..............................\n",
      "[CV]  max_features=auto, n_estimators=40, score=0.7862802079946392, total= 8.0min\n",
      "[CV] max_features=auto, n_estimators=40 ..............................\n",
      "[CV]  max_features=auto, n_estimators=40, score=0.8037341429660856, total= 7.8min\n",
      "[CV] max_features=auto, n_estimators=40 ..............................\n",
      "[CV]  max_features=auto, n_estimators=40, score=0.7970048398509275, total= 8.0min\n",
      "[CV] max_features=auto, n_estimators=50 ..............................\n",
      "[CV]  max_features=auto, n_estimators=50, score=0.8007239610970616, total= 9.9min\n",
      "[CV] max_features=auto, n_estimators=50 ..............................\n",
      "[CV]  max_features=auto, n_estimators=50, score=0.8030194564740423, total=10.3min\n",
      "[CV] max_features=auto, n_estimators=50 ..............................\n",
      "[CV]  max_features=auto, n_estimators=50, score=0.7877101923961282, total= 9.5min\n",
      "[CV] max_features=auto, n_estimators=50 ..............................\n",
      "[CV]  max_features=auto, n_estimators=50, score=0.8031011298748545, total= 9.3min\n",
      "[CV] max_features=auto, n_estimators=50 ..............................\n",
      "[CV]  max_features=auto, n_estimators=50, score=0.7987040851028651, total= 9.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 147.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 36min 1s, sys: 2min 4s, total: 2h 38min 6s\n",
      "Wall time: 2h 39min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': ['auto'], 'n_estimators': [20, 30, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_features': ['auto'],\n",
    "          'n_estimators': [20, 30, 40, 50]}\n",
    "\n",
    "forest_cv = GridSearchCV(RandomForestRegressor(),params, cv=5,verbose=3)\n",
    "%time forest_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 4.15 s, total: 20.1 s\n",
      "Wall time: 20.4 s\n",
      "Best Parameters: {'max_features': 'auto', 'n_estimators': 50}\n",
      "Best score is 0.7986517713325384\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = forest_cv.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters: {}\".format(forest_cv.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3656619998336051"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R-Squared: 79.95%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model R-Squared: {:.2f}%\".format(100*forest_cv.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a value of **0.3656**, RMSLE decreased compared to Linear Regression and SVM. So far Random Forest has performed better than any other model with not much of tuning. $R^2$ of the model is **79.95%**. However, fitting time was high compared to the previous models at **2hr 39min**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost <a name='xgboost'></a>\n",
    "***\n",
    "XGBoost builds really short and simple decision trees iteratively. Each tree is called a \"weak learner\" for their high bias. The algorithm goes on by sequentially building more weak learners, each one correcting the previous tree until a stopping condition is reached, such as the number of trees (n_estimators) to build. In this case, it will be limited to 50 because due to the large data it does become computationally expensive. First, let's use xgboost with no hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 500 ms, total: 13 s\n",
      "Wall time: 13.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBRegressor(n_estimators=10)\n",
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 174 ms, sys: 81.2 ms, total: 256 ms\n",
      "Wall time: 265 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5694031683493537"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R-Squared: 37.13%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model R-Squared: {:.2f}%\".format(100*clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no hyperparameter tuning, the model does worse than our base model linear regression in $R^2$ and rmsle. RMSLE is **0.5694** and $R^2$ is **37.13%.** Now let's tune XGBoost and check if the model gives a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning XGBoost <a name='tuning'></a>\n",
    "***\n",
    "Tuning is possible for really small datasets, but as the data grows, training time grows too, and each step in the tuning process becomes more expensive. Here we will tune only 8 hyperparameters that have big impact on performance.\n",
    "\n",
    "Since in this case the dataset is large (1.4 million entries), XGBRegressor was tested a few times with different parameters until it got a good enough solution. It would be necessary to test all combinations to ensure the optimal solution. This notebook will only show the best parameters for simplicity. For more details of how this parameters were chosen, please refer to the notebook [Tuning XGBoost](https://github.com/emmpew/datascience/blob/master/capstone_project/tuning_xgboost.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 449 ms, total: 2min 45s\n",
      "Wall time: 2min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=10, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 8\n",
    "min_child_weight = 10\n",
    "subsample = 1.0\n",
    "colsample_bytree = 1.0\n",
    "objective = 'reg:linear'\n",
    "num_estimators = 50\n",
    "# learning_rate = 0.4\n",
    "# reg_lambda=4\n",
    "\n",
    "clf = XGBRegressor(max_depth=max_depth,\n",
    "                min_child_weight=min_child_weight,\n",
    "                subsample=subsample,\n",
    "                colsample_bytree=colsample_bytree,\n",
    "                objective=objective,\n",
    "                n_estimators=num_estimators)\n",
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 s, sys: 47.3 ms, total: 2.17 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38501177796054564"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R-Squared: 78.69%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model R-Squared: {:.2f}%\".format(100*clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only tuning 5 of more than 20 hyperparameters, XGBoost does not do better than Random Forest. RMSLE is **0.3850** with $R^2$ of **78.69%**. Even though $R^2$ slighlty improved compared to Random Forest, tuning the hyperparmaters took more time (a notebook was dedicated to tuning XGBoost). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig =  plt.figure(figsize = (15,15))\n",
    "axes = fig.add_subplot(111)\n",
    "xgb.plot_importance(clf,ax = axes,height =0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features are the pickup_hour coordinates and the least important store_and_fwd_flag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conclusion <a name=\"conclusion\"></a>\n",
    "***\n",
    "\n",
    "Public transportation within New York City is relatively inexpensive, convenient and efficient. Taxis are essential part of the city. This project shows several characteristics of taxi rides, such as rush hours, GPS precision, average speed of taxis per hour, pickup and dropoff activity, etc. Through out the project data wrangling, exploratoty data analys, data cleaning and feature engineering was used to explore, analyze and make conclusions of the data. Below are some of the most important findings of the project:\n",
    "\n",
    "- Most of the taxi trips in the data were between 3 to 50 minutes. \n",
    "- Most of the activity happened in Manhattan. As well, there was some activity in the airports J.F. Kennedy and La Guardia. \n",
    "- Daily pickups during January 2016 and June 2016 were fairly homogeneous. However, there was a drop in demand near the end of January. From January 22 to 24, 2016, there was a blizzard that hit the East Coast. According to [weather.gov](https://www.weather.gov/okx/Blizzard_Jan2016), Central Park, NY received 27.5\" of snow, which is the largest snowstorm since records began in 1869.\n",
    "- The busiest day during the week for taxi drivers in NYC was Friday and the slowest day was Monday. \n",
    "- The passenger count showed that most of the taxi trips carry only one passenger.\n",
    "- The number of pickups per hour was higher at night with a peak between 6 and 7 PM when most people get out of work. \n",
    "- At around 5 in the morning, the taxi demand was the lowest. There is a rise of demand thoughout the day.\n",
    "- Most taxis sent the taxi trip information immediately and only few of them had an issue connecting to the server and had to store it. \n",
    "- There were 2 different vendors in the data and vendor 2 had more trips in the 6 month period in 2016.\n",
    "- The response variable trip_duration had no linear relationship with any of the features.\n",
    "- The GPS precision of the taxis varied from 1 up to 15 decimals. According to the [Degree Precision vs. Length Table](https://en.wikipedia.org/wiki/Decimal_degrees), a coordinate with 15 decimals would be equal to 0.1 nanometer(the size of an atom!), which sounds unrealistic for a taxi. In this project, all coordinates were rounded to 5 decimals, which is worth up to 1.1 m. According to Wikipedia, it distinguishes trees from each other which makes a good precision for a big city.\n",
    "- There was a really high demand after midnight on Friday, Saturday and Sunday. \n",
    "- For the 7 days of the week the demand was really low around 5 AM.\n",
    "- There was high demand between 7 and 10 AM from Monday to Friday.\n",
    "- Taxi demand stabilizes after 10 AM until 4 PM for all of the days in the week but still being pretty high.\n",
    "- At night, demand starts to slow down except on Fridays and Saturdays.\n",
    "\n",
    "These are just a few of the findings. For a more in depth analysis, please refer to this notebook. Just remember, even if your next [taxi driver](https://www.youtube.com/watch?v=kAd57FSAtMw) in NYC is really good at doing his job or has 5 stars on your favorite ridesharing app, traffic is just part of that NYC life unless it's 5 am."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results <a name=\"results\"></a>\n",
    "***\n",
    "\n",
    "Four different supervised regression algorithms were used to model the data. Below is a table that shows the $R^2$, fitting time, prediction time and RMSLE of each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fitting Time</th>\n",
       "      <th>Prediction Time</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>16.2 s</td>\n",
       "      <td>78.2 ms</td>\n",
       "      <td>55.79%</td>\n",
       "      <td>0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>1min 44s</td>\n",
       "      <td>117 ms</td>\n",
       "      <td>50.38%</td>\n",
       "      <td>0.4899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>2hr 39min</td>\n",
       "      <td>20.4 s</td>\n",
       "      <td>79.95%</td>\n",
       "      <td>0.3656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>~2hr</td>\n",
       "      <td>2.16 s</td>\n",
       "      <td>78.74%</td>\n",
       "      <td>0.3840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Fitting Time Prediction Time R-Squared   RMSLE\n",
       "Linear Regression       16.2 s         78.2 ms    55.79%  0.5397\n",
       "SVM                   1min 44s          117 ms    50.38%  0.4899\n",
       "Random Forest        2hr 39min          20.4 s    79.95%  0.3656\n",
       "XGBoost                   ~2hr          2.16 s    78.74%  0.3840"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'RMSLE': {'Linear Regression': 0.5397, 'SVM': 0.4899, 'Random Forest': 0.3656, 'XGBoost': 0.3840},\n",
    "     'R-Squared': {'Linear Regression': '55.79%', 'SVM': '50.38%', 'Random Forest': '79.95%', 'XGBoost': '78.74%'}, \n",
    "     'Fitting Time': {'Linear Regression': '16.2 s', 'SVM': '1min 44s', 'Random Forest': '2hr 39min', 'XGBoost': '~2hr'},\n",
    "     'Prediction Time': {'Linear Regression': '78.2 ms', 'SVM': '117 ms', 'Random Forest': '20.4 s', 'XGBoost': '2.16 s'}}\n",
    "df = pd.DataFrame(d).reindex(index = ['Linear Regression','SVM','Random Forest','XGBoost'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal of the project was to reduce RMSLE, Random Forest gave the best result with **0.3656** making this project to the **38th place** on the [Kaggle Leaderboard](https://www.kaggle.com/c/nyc-taxi-trip-duration/leaderboard). XGBoost gave a close result; however, the time spent tuning XGBoost was already high, in fact there is a separate notebook just for [Tuning XGBoost](https://github.com/emmpew/datascience/blob/master/capstone_project/tuning_xgboost.ipynb). It would require tuning more parameters and more fitting time to make the popular XGBoost perform better than Random Forest. For this project, Random Forest was the easiest to tune and gave the best results. It needed 50 n_estimators to get the lowest RMSLE. The $R^2$ of the model was **79.95%** making this project a success. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations <a name=\"recommendations\"></a>\n",
    "***\n",
    "This is just the beginning of predicting a NYC taxi trip. There is a lot more that can be done to improve RMSLE. \n",
    "\n",
    "Some ways to improve RMSLE:\n",
    "\n",
    "- Testing for more possible hyperparameter values for Random Forest and XGBoost as well. XGBoost tends to be a more powerful algorithm; however, in this project only 5 parameters were tuned.\n",
    "- More in depth data cleaning \n",
    "- More feature engineering relevant to the dataset.\n",
    "- Trying another model that would give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
